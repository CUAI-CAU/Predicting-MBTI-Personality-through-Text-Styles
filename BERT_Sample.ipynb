{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[K     |████████████████████████████████| 769 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (2020.10.15)\n",
      "Requirement already satisfied: requests in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (4.50.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (1.18.5)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/super/anaconda3/lib/python3.8/site-packages (from transformers==3.0.2) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/super/anaconda3/lib/python3.8/site-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
      "Requirement already satisfied: six in /home/super/anaconda3/lib/python3.8/site-packages (from packaging->transformers==3.0.2) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/super/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/super/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/super/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.0.2) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/super/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/super/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==3.0.2) (0.17.0)\n",
      "Requirement already satisfied: click in /home/super/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 39 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in'\n",
    "DATA_OUT_PATH = \"data_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9521, 118741, 35506, 24982, 48549, 100, 9521, 118741, 102]\n",
      "['[ C L S ]', '안', '# # 녕', '# # 하', '# # 세', '# # 요', '[ U N K ]', '안', '# # 녕', '[ S E P ]']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"안녕하세요 ㅋㅋㅋ 안녕 \"\n",
    "\n",
    "encode = tokenizer.encode(test_sentence)\n",
    "token_print = [tokenizer.decode(token) for token in encode]\n",
    "\n",
    "print(encode)\n",
    "print(token_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9521, 118741, 35506, 24982, 48549, 100, 9521, 118741, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요 [UNK] 안녕 [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "kor_encode = tokenizer.encode(\"안녕하세요 ㅋㅋㅋ 안녕\")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "# [101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
    "print(eng_encode)\n",
    "# [101, 31178, 11356, 102]\n",
    "print(kor_decode)\n",
    "# [CLS] 안녕하세요, 반갑습니다 [SEP]\n",
    "print(eng_decode)\n",
    "# [CLS] Hello world [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험\n",
    "기본적으로 한국어 데이터셋을 이용해야 하겠지만 주어진 모델이 영어이기 때문에 적용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 영화 감정 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"ratings_train.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data = train_data.dropna()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "\n",
    "# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n",
    "\n",
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149995/149995 [00:47<00:00, 3158.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 149995, # labels: 149995\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data[:1000] # for test\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train_data[\"document\"], train_data[\"label\"]), total=len(train_data)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "train_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks, train_movie_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_movie_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101    100    119    119    119   9928  58823  30005  11664   9757\n",
      " 118823  30858  18227 119219    119    119    119    119   9580  41605\n",
      "  25486  12310  20626  23466   8843 118986  12508   9523  17196  16439\n",
      "    102      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[CLS] [UNK]... 포스터보고 초딩영화줄.... 오버연기조차 가볍지 않구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이: 39\n",
    "input_id = train_movie_input_ids[1]\n",
    "attention_mask = train_movie_attention_masks[1]\n",
    "token_type_id = train_movie_type_ids[1]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"classifier\")\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1] \n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비하기\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/tf2_bert_naver_movie -- Folder already exists \n",
      "\n",
      "Epoch 1/3\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8114\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85210, saving model to data_out/tf2_bert_naver_movie/weights.h5\n",
      "3750/3750 [==============================] - 2674s 713ms/step - loss: 0.4057 - accuracy: 0.8114 - val_loss: 0.3366 - val_accuracy: 0.8521\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8630\n",
      "Epoch 00002: val_accuracy improved from 0.85210 to 0.85840, saving model to data_out/tf2_bert_naver_movie/weights.h5\n",
      "3750/3750 [==============================] - 2778s 741ms/step - loss: 0.3139 - accuracy: 0.8630 - val_loss: 0.3307 - val_accuracy: 0.8584\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.8916\n",
      "Epoch 00003: val_accuracy improved from 0.85840 to 0.86246, saving model to data_out/tf2_bert_naver_movie/weights.h5\n",
      "3750/3750 [==============================] - 2738s 730ms/step - loss: 0.2600 - accuracy: 0.8916 - val_loss: 0.3203 - val_accuracy: 0.8625\n",
      "{'loss': [0.4057096242904663, 0.3139273226261139, 0.25998347997665405], 'accuracy': [0.8113770484924316, 0.8630454540252686, 0.8915714025497437], 'val_loss': [0.33655866980552673, 0.33065691590309143, 0.3203417658805847], 'val_accuracy': [0.8520950675010681, 0.8583952784538269, 0.8624621033668518]}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_naver_movie\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = cls_model.fit(train_movie_inputs, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "test_data = test_data.dropna()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49997it [00:16, 3108.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sents, labels 49997, 49997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent, test_label in tqdm(zip(test_data[\"document\"], test_data[\"label\"])):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        test_data_labels.append(test_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "\n",
    "test_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "test_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks, test_movie_type_ids)\n",
    "\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(test_movie_input_ids), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 45s 925ms/step - loss: 0.3244 - accuracy: 0.8610\n",
      "test loss, test acc:  [0.3243924677371979, 0.8610316514968872]\n"
     ]
    }
   ],
   "source": [
    "results = cls_model.evaluate(test_movie_inputs, test_data_labels, batch_size=1024)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-14e7a524ff3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_movie_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_movie_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(test_movie_inputs[1])\n",
    "print(test_data_labels[1])\n",
    "prediction = cls_model.predict(test_movie_inputs[1])\n",
    "print(np.argmax(prediction[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
